{"title":"Data Collection","markdown":{"yaml":{"title":"Data Collection","subtitle":"Sampling Strategy, Street View Download, and Census Integration"},"headingText":"The Foundation of Spatial Analysis","containsRefs":false,"markdown":"\n\n\nAny study of urban happiness must begin with data that captures both the visual character of places and the social context of neighborhoods. Our pipeline integrates three distinct sources: road network data for systematic sampling, Google Street View imagery for visual features, and Census data for socioeconomic context.\n\n## Philadelphia as Study Area\n\nPhiladelphia offers an ideal laboratory for studying urban happiness. The city contains everything from the dense, walkable streets of Center City to quiet residential suburbs in the Northeast and Northwest, industrial zones along the Delaware River, and historic neighborhoods like Society Hill and Germantown. This diversity allows us to examine how different urban forms relate to perceived happiness.\n\n### Where Are the Happy Places?\n\nThe 28 happiness points collected from Drexel University students reveal a striking spatial pattern:\n\n<div style=\"width: 100%; height: 600px; border-radius: 12px; overflow: hidden; box-shadow: 0 8px 32px rgba(0,0,0,0.3);\">\n<iframe src=\"../images/philadelphia_happiness_map.html\" width=\"100%\" height=\"100%\" style=\"border: none;\"></iframe>\n</div>\n\n*Interactive map: Click on markers to view details. Drag to rotate, scroll to zoom.*\n\nThe clustering is immediately apparent. Most happiness points concentrate in the urban core—near commercial districts, cultural institutions, and the university campus. Several align along the Delaware and Schuylkill Rivers, where waterfront parks and trails provide recreational amenities. Notably absent are the outer residential neighborhoods that comprise most of Philadelphia's land area. This pattern already hints at what our analysis will confirm: happiness is associated with urban vitality rather than quiet residential settings.\n\n---\n\n## Generating Sampling Points\n\nFollowing the approach established by Li & Ratti (2019), we generate sampling points at regular intervals along road centerlines. A **200-meter interval** balances comprehensive coverage against computational feasibility, producing approximately 40,000 points distributed across Philadelphia's street network.\n\nThe projection system matters more than it might seem. We use **NAD 1983 Pennsylvania South (EPSG:2272)** rather than WGS84 because at Philadelphia's latitude, unprojected coordinates would introduce roughly 15% error in distance calculations due to meridian convergence.\n\n```python\n#| eval: false\n\nimport geopandas as gpd\nimport pandas as pd\nfrom shapely.geometry import Point\nfrom pathlib import Path\n\ndef generate_sampling_points(centerline_path, boundary_path, interval_m=200):\n    \"\"\"\n    Generate sampling points along road centerlines at regular intervals.\n    \n    Parameters:\n    -----------\n    centerline_path : str\n        Path to road centerline shapefile\n    boundary_path : str\n        Path to city boundary shapefile\n    interval_m : float\n        Sampling interval in meters (default: 200)\n    \n    Returns:\n    --------\n    GeoDataFrame with sampling points\n    \"\"\"\n    # Define projection - NAD 1983 Pennsylvania South (ft)\n    target_crs = \"EPSG:2272\"\n    \n    # Read and project data\n    centerline = gpd.read_file(centerline_path).to_crs(target_crs)\n    boundary = gpd.read_file(boundary_path).to_crs(target_crs)\n    \n    # Clip roads to city boundary\n    centerline_clipped = gpd.clip(centerline, boundary)\n    \n    # Convert interval from meters to feet\n    interval_ft = interval_m * 3.28084\n    \n    # Generate points along each road segment\n    sample_points = []\n    sample_attributes = []\n    \n    for idx, row in centerline_clipped.iterrows():\n        line = row.geometry\n        \n        if line.geom_type == 'LineString':\n            _process_linestring(line, idx, interval_ft, sample_points, sample_attributes)\n        elif line.geom_type == 'MultiLineString':\n            for sub_idx, single_line in enumerate(line.geoms):\n                _process_linestring(single_line, f\"{idx}_{sub_idx}\", interval_ft, \n                                   sample_points, sample_attributes)\n    \n    # Create GeoDataFrame\n    gdf = gpd.GeoDataFrame(sample_attributes, geometry=sample_points, crs=target_crs)\n    gdf['point_id'] = range(1, len(gdf) + 1)\n    \n    # Add WGS84 coordinates for API calls\n    gdf_wgs84 = gdf.to_crs(\"EPSG:4326\")\n    gdf['longitude'] = gdf_wgs84.geometry.x\n    gdf['latitude'] = gdf_wgs84.geometry.y\n    \n    return gdf\n\n\ndef _process_linestring(line, street_id, interval_ft, points_list, attrs_list):\n    \"\"\"Helper function to process a single LineString geometry.\"\"\"\n    line_length = line.length\n    num_points = int(line_length / interval_ft) + 1\n    \n    for i in range(num_points):\n        distance = i * interval_ft\n        if distance <= line_length:\n            point = line.interpolate(distance)\n            points_list.append(point)\n            attrs_list.append({\n                'point_type': 'road_sample',\n                'street_id': street_id,\n                'distance_ft': round(distance, 2)\n            })\n```\n\nPhiladelphia's road data contains both `LineString` and `MultiLineString` geometries—the latter occurring where a single road record spans multiple disconnected segments, such as roads split by parks or rivers. We process each component separately to maintain accurate sampling. By clipping to the city boundary first, we ensure all sampling points fall within Philadelphia's limits.\n\n| Metric | Value |\n|--------|-------|\n| Total road segments | ~47,000 |\n| Sampling interval | 200 meters |\n| Generated points | ~40,000 |\n| Coverage area | 142 sq mi |\n\n---\n\n## Google Street View Download\n\nGoogle Street View provides the visual foundation for our analysis. Rather than using the standard Static API (which limits images to 640×640 pixels), we employ a **tile-based download method** that stitches together high-resolution panoramic images at 3328×1664 pixels—over 8× more pixels for semantic segmentation.\n\n```python\n#| eval: false\n\nimport requests\nfrom PIL import Image\nfrom io import BytesIO\nimport time\n\nclass GSVDownloader:\n    \"\"\"\n    Google Street View panorama downloader using tile stitching method.\n    \n    This approach downloads individual tiles and stitches them together,\n    providing higher resolution than the standard Static API limit.\n    \"\"\"\n    \n    def __init__(self, api_key):\n        self.api_key = api_key\n        self.metadata_url = \"https://maps.googleapis.com/maps/api/streetview/metadata\"\n        \n        # Tile configuration for each zoom level\n        self.grid_sizes = {\n            0: (1, 1),    # 512 x 512\n            1: (2, 1),    # 1024 x 512\n            2: (4, 2),    # 2048 x 1024\n            3: (7, 4),    # 3584 x 2048 -> cropped to 3328 x 1664\n            4: (13, 7),   # 6656 x 3584\n            5: (26, 13)   # 13312 x 6656\n        }\n    \n    def get_metadata(self, lat, lon):\n        \"\"\"\n        Retrieve GSV metadata for a location.\n        \n        Returns pano_id, capture date, and actual location if available.\n        \"\"\"\n        params = {\n            'location': f\"{lat},{lon}\",\n            'key': self.api_key\n        }\n        \n        response = requests.get(self.metadata_url, params=params, timeout=10)\n        data = response.json()\n        \n        if data.get('status') == 'OK':\n            return {\n                'pano_id': data['pano_id'],\n                'lat': data['location']['lat'],\n                'lon': data['location']['lng'],\n                'date': data.get('date'),\n                'status': 'OK'\n            }\n        return {'status': data.get('status', 'UNKNOWN')}\n    \n    def download_panorama(self, pano_id, output_path=None, zoom=3, tile_size=512):\n        \"\"\"\n        Download and stitch panorama tiles.\n        \"\"\"\n        cols, rows = self.grid_sizes[zoom]\n        \n        # Create blank canvas\n        panorama = Image.new('RGB', (cols * tile_size, rows * tile_size))\n        \n        # Download and place each tile\n        for y in range(rows):\n            for x in range(cols):\n                tile_url = (f\"https://cbk0.google.com/cbk?\"\n                           f\"output=tile&panoid={pano_id}&zoom={zoom}&x={x}&y={y}\")\n                \n                try:\n                    response = requests.get(tile_url, timeout=10)\n                    if response.status_code == 200:\n                        tile = Image.open(BytesIO(response.content))\n                        panorama.paste(tile, (x * tile_size, y * tile_size))\n                except Exception as e:\n                    print(f\"Failed to download tile ({x},{y}): {e}\")\n                \n                time.sleep(0.02)  # Rate limiting\n        \n        if output_path:\n            panorama.save(output_path, 'JPEG', quality=95)\n        \n        return panorama\n```\n\nThe tile-based approach offers practical advantages: direct tile access produces clean images without the Google logo watermark, and tile requests don't count against the paid Static API quota.\n\nCoverage analysis revealed that approximately **98% of sampling points** have available Street View imagery. The ~2% without coverage typically fall in recently developed areas, private roads, or parks without street access.\n\n| Metric | Value |\n|--------|-------|\n| Points with GSV metadata | ~40,000 |\n| Image dimensions | 3328 × 1664 px |\n| Total storage | ~60 GB |\n\n### A Visual Tour of Philadelphia\n\nThe downloaded panoramas capture the remarkable diversity of Philadelphia's urban fabric:\n\n::: {layout-ncol=2}\n\n![Urban park environment](../images/jJkm1xU1q2wDq3tZ6HIXKA.jpg)\n\n![Community garden street](../images/7fxU5aDxWqvtI3lmblf2RQ.jpg)\n\n:::\n\n::: {layout-ncol=2}\n\n![Commercial district](../images/gkG_zMm_kd5sezfg4OcyCw.jpg)\n\n![Highway infrastructure](../images/177Csfd8e6xqewWrF-dq5A.jpg)\n\n:::\n\nFrom lush parks and intimate residential streets to commercial corridors and highway infrastructure—this variation is essential for building a model that can distinguish environmental characteristics associated with happiness. The 28 happiness points from Drexel University's study are included in our sampling points dataset and processed alongside all other road samples.\n\n---\n\n## Census Data Integration\n\nThe visual character of a street tells only part of the story. A clean street in a high-income neighborhood may feel different from an identical street in a high-poverty area due to ambient factors—noise levels, social activity patterns, maintenance standards—that aren't directly visible in a photograph.\n\nWe selected Census variables that prior research has linked to neighborhood quality and perceived well-being:\n\n```python\n#| eval: false\n\nclass CensusDownloader:\n    \"\"\"\n    Download and process Census ACS 5-year estimates.\n    \n    Focuses on variables related to:\n    - Demographics (age, race)\n    - Economic status (income, poverty)\n    - Education\n    - Housing characteristics\n    \"\"\"\n    \n    def __init__(self, api_key):\n        self.api_key = api_key\n        self.base_url = \"https://api.census.gov/data\"\n        \n        # Philadelphia: State 42 (PA), County 101\n        self.state = \"42\"\n        self.county = \"101\"\n        \n        # ACS variables of interest\n        self.variables = {\n            # Population\n            'B01003_001E': 'total_pop',\n            'B01002_001E': 'median_age',\n            \n            # Race\n            'B02001_002E': 'pop_white',\n            'B02001_003E': 'pop_black',\n            \n            # Income & Poverty\n            'B19013_001E': 'median_income',\n            'B17001_002E': 'pop_poverty',\n            \n            # Education (25+)\n            'B15003_022E': 'pop_bachelor',\n            'B15003_023E': 'pop_master',\n            'B15003_025E': 'pop_doctorate',\n            \n            # Housing\n            'B25003_001E': 'total_housing',\n            'B25003_002E': 'owner_occupied',\n            \n            # Employment\n            'B23025_003E': 'labor_force',\n            'B23025_005E': 'unemployed',\n        }\n    \n    def download(self, year=2022):\n        \"\"\"Download ACS 5-year estimates for Philadelphia Census Tracts.\"\"\"\n        var_string = ','.join(self.variables.keys())\n        \n        url = f\"{self.base_url}/{year}/acs/acs5\"\n        params = {\n            'get': f'NAME,{var_string}',\n            'for': 'tract:*',\n            'in': f'state:{self.state} county:{self.county}',\n            'key': self.api_key\n        }\n        \n        response = requests.get(url, params=params, timeout=60)\n        data = response.json()\n        \n        # Convert to DataFrame\n        df = pd.DataFrame(data[1:], columns=data[0])\n        \n        # Rename columns\n        for code, name in self.variables.items():\n            if code in df.columns:\n                df = df.rename(columns={code: name})\n        \n        # Create GEOID for spatial join\n        df['GEOID'] = df['state'] + df['county'] + df['tract']\n        \n        return df\n    \n    def calculate_rates(self, df):\n        \"\"\"Calculate derived variables (percentages and rates).\"\"\"\n        # Safely divide, handling zeros\n        def safe_div(num, denom):\n            return num / denom.where(denom > 0)\n        \n        df['pct_white'] = safe_div(df['pop_white'], df['total_pop'])\n        df['poverty_rate'] = safe_div(df['pop_poverty'], df['total_pop'])\n        \n        # College education rate\n        df['pop_college'] = (df['pop_bachelor'].fillna(0) + \n                            df['pop_master'].fillna(0) + \n                            df['pop_doctorate'].fillna(0))\n        df['pct_college'] = safe_div(df['pop_college'], df['total_pop'])\n        \n        df['pct_owner_occupied'] = safe_div(df['owner_occupied'], df['total_housing'])\n        df['unemployment_rate'] = safe_div(df['unemployed'], df['labor_force'])\n        \n        return df\n```\n\nA data quality note: the Census API returns **-666666666** for missing or suppressed values, typically in tracts with very small populations where releasing data would compromise anonymity. We replace these with `NaN` before analysis.\n\nThere's an inherent limitation in using Census data at the tract level. Philadelphia has 384 tracts for a city of 1.58 million people, meaning each tract averages about 4,100 residents. Any sampling point within a tract receives the same socioeconomic values. A street corner in a nominally wealthy tract may actually be surrounded by lower-income residents, but our data cannot capture this intra-tract variation—an ecological fallacy risk worth keeping in mind.\n\n| Variable | Min | Mean | Max |\n|----------|-----|------|-----|\n| Median Income | $13,125 | $52,847 | $250,000+ |\n| Poverty Rate | 0.0% | 22.4% | 68.2% |\n| College Rate | 2.1% | 31.2% | 89.4% |\n| Owner-Occupied | 0.0% | 52.3% | 97.8% |\n\n---\n\n## The Final Dataset\n\nAfter completing all data collection steps, we produce a unified dataset containing approximately 40,000 observations. Each point carries 6 visual features (from semantic segmentation, covered next), 8 socioeconomic features (from Census), and a PU Learning label indicating whether the point is a labeled happiness location or unlabeled.\n\nThis dataset forms the foundation for our analysis of what makes places feel happy.\n\n\n<div class=\"sidebar-authors\">\n<div><img src=\"../images/upenn.jpg\" alt=\"Penn\" style=\"height: 26px;\"></div>\n<div><a href=\"../index.qmd#contributors\">Fan Yang & Zhiyuan Zhao</a></div>\n</div>","srcMarkdownNoYaml":"\n\n## The Foundation of Spatial Analysis\n\nAny study of urban happiness must begin with data that captures both the visual character of places and the social context of neighborhoods. Our pipeline integrates three distinct sources: road network data for systematic sampling, Google Street View imagery for visual features, and Census data for socioeconomic context.\n\n## Philadelphia as Study Area\n\nPhiladelphia offers an ideal laboratory for studying urban happiness. The city contains everything from the dense, walkable streets of Center City to quiet residential suburbs in the Northeast and Northwest, industrial zones along the Delaware River, and historic neighborhoods like Society Hill and Germantown. This diversity allows us to examine how different urban forms relate to perceived happiness.\n\n### Where Are the Happy Places?\n\nThe 28 happiness points collected from Drexel University students reveal a striking spatial pattern:\n\n<div style=\"width: 100%; height: 600px; border-radius: 12px; overflow: hidden; box-shadow: 0 8px 32px rgba(0,0,0,0.3);\">\n<iframe src=\"../images/philadelphia_happiness_map.html\" width=\"100%\" height=\"100%\" style=\"border: none;\"></iframe>\n</div>\n\n*Interactive map: Click on markers to view details. Drag to rotate, scroll to zoom.*\n\nThe clustering is immediately apparent. Most happiness points concentrate in the urban core—near commercial districts, cultural institutions, and the university campus. Several align along the Delaware and Schuylkill Rivers, where waterfront parks and trails provide recreational amenities. Notably absent are the outer residential neighborhoods that comprise most of Philadelphia's land area. This pattern already hints at what our analysis will confirm: happiness is associated with urban vitality rather than quiet residential settings.\n\n---\n\n## Generating Sampling Points\n\nFollowing the approach established by Li & Ratti (2019), we generate sampling points at regular intervals along road centerlines. A **200-meter interval** balances comprehensive coverage against computational feasibility, producing approximately 40,000 points distributed across Philadelphia's street network.\n\nThe projection system matters more than it might seem. We use **NAD 1983 Pennsylvania South (EPSG:2272)** rather than WGS84 because at Philadelphia's latitude, unprojected coordinates would introduce roughly 15% error in distance calculations due to meridian convergence.\n\n```python\n#| eval: false\n\nimport geopandas as gpd\nimport pandas as pd\nfrom shapely.geometry import Point\nfrom pathlib import Path\n\ndef generate_sampling_points(centerline_path, boundary_path, interval_m=200):\n    \"\"\"\n    Generate sampling points along road centerlines at regular intervals.\n    \n    Parameters:\n    -----------\n    centerline_path : str\n        Path to road centerline shapefile\n    boundary_path : str\n        Path to city boundary shapefile\n    interval_m : float\n        Sampling interval in meters (default: 200)\n    \n    Returns:\n    --------\n    GeoDataFrame with sampling points\n    \"\"\"\n    # Define projection - NAD 1983 Pennsylvania South (ft)\n    target_crs = \"EPSG:2272\"\n    \n    # Read and project data\n    centerline = gpd.read_file(centerline_path).to_crs(target_crs)\n    boundary = gpd.read_file(boundary_path).to_crs(target_crs)\n    \n    # Clip roads to city boundary\n    centerline_clipped = gpd.clip(centerline, boundary)\n    \n    # Convert interval from meters to feet\n    interval_ft = interval_m * 3.28084\n    \n    # Generate points along each road segment\n    sample_points = []\n    sample_attributes = []\n    \n    for idx, row in centerline_clipped.iterrows():\n        line = row.geometry\n        \n        if line.geom_type == 'LineString':\n            _process_linestring(line, idx, interval_ft, sample_points, sample_attributes)\n        elif line.geom_type == 'MultiLineString':\n            for sub_idx, single_line in enumerate(line.geoms):\n                _process_linestring(single_line, f\"{idx}_{sub_idx}\", interval_ft, \n                                   sample_points, sample_attributes)\n    \n    # Create GeoDataFrame\n    gdf = gpd.GeoDataFrame(sample_attributes, geometry=sample_points, crs=target_crs)\n    gdf['point_id'] = range(1, len(gdf) + 1)\n    \n    # Add WGS84 coordinates for API calls\n    gdf_wgs84 = gdf.to_crs(\"EPSG:4326\")\n    gdf['longitude'] = gdf_wgs84.geometry.x\n    gdf['latitude'] = gdf_wgs84.geometry.y\n    \n    return gdf\n\n\ndef _process_linestring(line, street_id, interval_ft, points_list, attrs_list):\n    \"\"\"Helper function to process a single LineString geometry.\"\"\"\n    line_length = line.length\n    num_points = int(line_length / interval_ft) + 1\n    \n    for i in range(num_points):\n        distance = i * interval_ft\n        if distance <= line_length:\n            point = line.interpolate(distance)\n            points_list.append(point)\n            attrs_list.append({\n                'point_type': 'road_sample',\n                'street_id': street_id,\n                'distance_ft': round(distance, 2)\n            })\n```\n\nPhiladelphia's road data contains both `LineString` and `MultiLineString` geometries—the latter occurring where a single road record spans multiple disconnected segments, such as roads split by parks or rivers. We process each component separately to maintain accurate sampling. By clipping to the city boundary first, we ensure all sampling points fall within Philadelphia's limits.\n\n| Metric | Value |\n|--------|-------|\n| Total road segments | ~47,000 |\n| Sampling interval | 200 meters |\n| Generated points | ~40,000 |\n| Coverage area | 142 sq mi |\n\n---\n\n## Google Street View Download\n\nGoogle Street View provides the visual foundation for our analysis. Rather than using the standard Static API (which limits images to 640×640 pixels), we employ a **tile-based download method** that stitches together high-resolution panoramic images at 3328×1664 pixels—over 8× more pixels for semantic segmentation.\n\n```python\n#| eval: false\n\nimport requests\nfrom PIL import Image\nfrom io import BytesIO\nimport time\n\nclass GSVDownloader:\n    \"\"\"\n    Google Street View panorama downloader using tile stitching method.\n    \n    This approach downloads individual tiles and stitches them together,\n    providing higher resolution than the standard Static API limit.\n    \"\"\"\n    \n    def __init__(self, api_key):\n        self.api_key = api_key\n        self.metadata_url = \"https://maps.googleapis.com/maps/api/streetview/metadata\"\n        \n        # Tile configuration for each zoom level\n        self.grid_sizes = {\n            0: (1, 1),    # 512 x 512\n            1: (2, 1),    # 1024 x 512\n            2: (4, 2),    # 2048 x 1024\n            3: (7, 4),    # 3584 x 2048 -> cropped to 3328 x 1664\n            4: (13, 7),   # 6656 x 3584\n            5: (26, 13)   # 13312 x 6656\n        }\n    \n    def get_metadata(self, lat, lon):\n        \"\"\"\n        Retrieve GSV metadata for a location.\n        \n        Returns pano_id, capture date, and actual location if available.\n        \"\"\"\n        params = {\n            'location': f\"{lat},{lon}\",\n            'key': self.api_key\n        }\n        \n        response = requests.get(self.metadata_url, params=params, timeout=10)\n        data = response.json()\n        \n        if data.get('status') == 'OK':\n            return {\n                'pano_id': data['pano_id'],\n                'lat': data['location']['lat'],\n                'lon': data['location']['lng'],\n                'date': data.get('date'),\n                'status': 'OK'\n            }\n        return {'status': data.get('status', 'UNKNOWN')}\n    \n    def download_panorama(self, pano_id, output_path=None, zoom=3, tile_size=512):\n        \"\"\"\n        Download and stitch panorama tiles.\n        \"\"\"\n        cols, rows = self.grid_sizes[zoom]\n        \n        # Create blank canvas\n        panorama = Image.new('RGB', (cols * tile_size, rows * tile_size))\n        \n        # Download and place each tile\n        for y in range(rows):\n            for x in range(cols):\n                tile_url = (f\"https://cbk0.google.com/cbk?\"\n                           f\"output=tile&panoid={pano_id}&zoom={zoom}&x={x}&y={y}\")\n                \n                try:\n                    response = requests.get(tile_url, timeout=10)\n                    if response.status_code == 200:\n                        tile = Image.open(BytesIO(response.content))\n                        panorama.paste(tile, (x * tile_size, y * tile_size))\n                except Exception as e:\n                    print(f\"Failed to download tile ({x},{y}): {e}\")\n                \n                time.sleep(0.02)  # Rate limiting\n        \n        if output_path:\n            panorama.save(output_path, 'JPEG', quality=95)\n        \n        return panorama\n```\n\nThe tile-based approach offers practical advantages: direct tile access produces clean images without the Google logo watermark, and tile requests don't count against the paid Static API quota.\n\nCoverage analysis revealed that approximately **98% of sampling points** have available Street View imagery. The ~2% without coverage typically fall in recently developed areas, private roads, or parks without street access.\n\n| Metric | Value |\n|--------|-------|\n| Points with GSV metadata | ~40,000 |\n| Image dimensions | 3328 × 1664 px |\n| Total storage | ~60 GB |\n\n### A Visual Tour of Philadelphia\n\nThe downloaded panoramas capture the remarkable diversity of Philadelphia's urban fabric:\n\n::: {layout-ncol=2}\n\n![Urban park environment](../images/jJkm1xU1q2wDq3tZ6HIXKA.jpg)\n\n![Community garden street](../images/7fxU5aDxWqvtI3lmblf2RQ.jpg)\n\n:::\n\n::: {layout-ncol=2}\n\n![Commercial district](../images/gkG_zMm_kd5sezfg4OcyCw.jpg)\n\n![Highway infrastructure](../images/177Csfd8e6xqewWrF-dq5A.jpg)\n\n:::\n\nFrom lush parks and intimate residential streets to commercial corridors and highway infrastructure—this variation is essential for building a model that can distinguish environmental characteristics associated with happiness. The 28 happiness points from Drexel University's study are included in our sampling points dataset and processed alongside all other road samples.\n\n---\n\n## Census Data Integration\n\nThe visual character of a street tells only part of the story. A clean street in a high-income neighborhood may feel different from an identical street in a high-poverty area due to ambient factors—noise levels, social activity patterns, maintenance standards—that aren't directly visible in a photograph.\n\nWe selected Census variables that prior research has linked to neighborhood quality and perceived well-being:\n\n```python\n#| eval: false\n\nclass CensusDownloader:\n    \"\"\"\n    Download and process Census ACS 5-year estimates.\n    \n    Focuses on variables related to:\n    - Demographics (age, race)\n    - Economic status (income, poverty)\n    - Education\n    - Housing characteristics\n    \"\"\"\n    \n    def __init__(self, api_key):\n        self.api_key = api_key\n        self.base_url = \"https://api.census.gov/data\"\n        \n        # Philadelphia: State 42 (PA), County 101\n        self.state = \"42\"\n        self.county = \"101\"\n        \n        # ACS variables of interest\n        self.variables = {\n            # Population\n            'B01003_001E': 'total_pop',\n            'B01002_001E': 'median_age',\n            \n            # Race\n            'B02001_002E': 'pop_white',\n            'B02001_003E': 'pop_black',\n            \n            # Income & Poverty\n            'B19013_001E': 'median_income',\n            'B17001_002E': 'pop_poverty',\n            \n            # Education (25+)\n            'B15003_022E': 'pop_bachelor',\n            'B15003_023E': 'pop_master',\n            'B15003_025E': 'pop_doctorate',\n            \n            # Housing\n            'B25003_001E': 'total_housing',\n            'B25003_002E': 'owner_occupied',\n            \n            # Employment\n            'B23025_003E': 'labor_force',\n            'B23025_005E': 'unemployed',\n        }\n    \n    def download(self, year=2022):\n        \"\"\"Download ACS 5-year estimates for Philadelphia Census Tracts.\"\"\"\n        var_string = ','.join(self.variables.keys())\n        \n        url = f\"{self.base_url}/{year}/acs/acs5\"\n        params = {\n            'get': f'NAME,{var_string}',\n            'for': 'tract:*',\n            'in': f'state:{self.state} county:{self.county}',\n            'key': self.api_key\n        }\n        \n        response = requests.get(url, params=params, timeout=60)\n        data = response.json()\n        \n        # Convert to DataFrame\n        df = pd.DataFrame(data[1:], columns=data[0])\n        \n        # Rename columns\n        for code, name in self.variables.items():\n            if code in df.columns:\n                df = df.rename(columns={code: name})\n        \n        # Create GEOID for spatial join\n        df['GEOID'] = df['state'] + df['county'] + df['tract']\n        \n        return df\n    \n    def calculate_rates(self, df):\n        \"\"\"Calculate derived variables (percentages and rates).\"\"\"\n        # Safely divide, handling zeros\n        def safe_div(num, denom):\n            return num / denom.where(denom > 0)\n        \n        df['pct_white'] = safe_div(df['pop_white'], df['total_pop'])\n        df['poverty_rate'] = safe_div(df['pop_poverty'], df['total_pop'])\n        \n        # College education rate\n        df['pop_college'] = (df['pop_bachelor'].fillna(0) + \n                            df['pop_master'].fillna(0) + \n                            df['pop_doctorate'].fillna(0))\n        df['pct_college'] = safe_div(df['pop_college'], df['total_pop'])\n        \n        df['pct_owner_occupied'] = safe_div(df['owner_occupied'], df['total_housing'])\n        df['unemployment_rate'] = safe_div(df['unemployed'], df['labor_force'])\n        \n        return df\n```\n\nA data quality note: the Census API returns **-666666666** for missing or suppressed values, typically in tracts with very small populations where releasing data would compromise anonymity. We replace these with `NaN` before analysis.\n\nThere's an inherent limitation in using Census data at the tract level. Philadelphia has 384 tracts for a city of 1.58 million people, meaning each tract averages about 4,100 residents. Any sampling point within a tract receives the same socioeconomic values. A street corner in a nominally wealthy tract may actually be surrounded by lower-income residents, but our data cannot capture this intra-tract variation—an ecological fallacy risk worth keeping in mind.\n\n| Variable | Min | Mean | Max |\n|----------|-----|------|-----|\n| Median Income | $13,125 | $52,847 | $250,000+ |\n| Poverty Rate | 0.0% | 22.4% | 68.2% |\n| College Rate | 2.1% | 31.2% | 89.4% |\n| Owner-Occupied | 0.0% | 52.3% | 97.8% |\n\n---\n\n## The Final Dataset\n\nAfter completing all data collection steps, we produce a unified dataset containing approximately 40,000 observations. Each point carries 6 visual features (from semantic segmentation, covered next), 8 socioeconomic features (from Census), and a PU Learning label indicating whether the point is a labeled happiness location or unlabeled.\n\nThis dataset forms the foundation for our analysis of what makes places feel happy.\n\n\n<div class=\"sidebar-authors\">\n<div><img src=\"../images/upenn.jpg\" alt=\"Penn\" style=\"height: 26px;\"></div>\n<div><a href=\"../index.qmd#contributors\">Fan Yang & Zhiyuan Zhao</a></div>\n</div>"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"message":false,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"output-file":"1-data-collection.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.24","theme":"cosmo","toc-location":"right","toc-title":"On this page","code-summary":"Show code","page-layout":"full","grid":{"sidebar-width":"250px","body-width":"1200px","margin-width":"200px"},"title":"Data Collection","subtitle":"Sampling Strategy, Street View Download, and Census Integration"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}